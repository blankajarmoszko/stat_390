{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred_var = 'Additional_Doses_Vax_Pct'\n",
    "\n",
    "data = pd.read_csv('df_post_eda.csv')\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.groupby('Date')[pred_var].mean()\n",
    "#df.set_index('Date', inplace=True)\n",
    "\n",
    "#subset data to be only dates and predictin variable values\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ff1c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp39-cp39-macosx_10_15_x86_64.whl (229.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 229.6 MB 11.0 MB/s eta 0:00:01    |████████████████                | 115.4 MB 1.9 MB/s eta 0:01:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[K     |████████████████████████████████| 440 kB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 16.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp39-cp39-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 25.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.0-cp37-abi3-macosx_10_9_universal2.whl (393 kB)\n",
      "\u001b[K     |████████████████████████████████| 393 kB 35.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 21.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl (24.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.5 MB 8.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.2-cp39-cp39-macosx_10_10_universal2.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 27.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting numpy>=1.23.5\n",
      "  Downloading numpy-1.26.2-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.6 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 62.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 73.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 18.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 26.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.0.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 21.4 MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 129.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/blankajarmoszko/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.2)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 14.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, ml-dtypes, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "scipy 1.7.1 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.2 which is incompatible.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.26.2 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.4 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.2 keras-2.14.0 libclang-16.0.6 markdown-3.5.1 ml-dtypes-0.2.0 numpy-1.26.2 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.25.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.2 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44003b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = df.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7935084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73506a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2eca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488da4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb077fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab27a1b",
   "metadata": {},
   "source": [
    "### LSTM w/ Window Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fbaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('airline-passengers.csv', usecols=[1], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
